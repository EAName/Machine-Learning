{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print( tf.__version__ )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASHION data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Label   Class\n",
    "0       T-shirt/top\n",
    "1       Trouser\n",
    "2       Pullover\n",
    "3       Dress\n",
    "4       Coat\n",
    "5       Sandal\n",
    "6       Shirt\n",
    "7       Sneaker\n",
    "8       Bag\n",
    "9       Ankle boot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in Fashion Data\n",
    "mnist = tf.keras.datasets.fashion_mnist # 28x28 Fashion Image Data\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "              'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMBER data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in Data\n",
    "# mnist = tf.keras.datasets.mnist # 28x28 Handwritten Digits 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the Data\n",
    "# x_train = tf.keras.utils.normalize( x_train, axis=1 )\n",
    "# x_test = tf.keras.utils.normalize( x_test, axis=1 )\n",
    "\n",
    "# Divide training and testing sets by 255 \n",
    "x_train = x_train / 255 \n",
    "x_test = x_test / 255 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(60000, 28, 28)\n",
      "<class 'numpy.ndarray'>\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print( type( x_train ) )\n",
    "print( x_train.shape )\n",
    "\n",
    "print( type( y_train ) )\n",
    "print( y_train.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape =  (28, 28)\n",
      "TOTAL SIZE =  784\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = x_train[0].shape\n",
    "print(\"Shape = \", INPUT_SHAPE )\n",
    "\n",
    "TOTAL_SIZE = INPUT_SHAPE[0] * INPUT_SHAPE[1]\n",
    "print(\"TOTAL SIZE = \", TOTAL_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomIndex( DATA ) :\n",
    "    return random.randint(0, DATA.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who= 293\n",
      "6\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.         0.07058824\n",
      "  0.58039216 0.20392157 0.06666667 0.27058824 0.20784314 0.\n",
      "  0.         0.00392157 0.00392157 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16470588\n",
      "  0.82352941 0.91372549 0.80392157 0.59215686 0.47058824 0.02745098\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06666667 0.16862745 0.25490196 0.15294118\n",
      "  0.30588235 0.90588235 0.76470588 0.31372549 0.49411765 0.50196078\n",
      "  0.32156863 0.18823529 0.07058824 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.03921569 0.2627451  0.28235294 0.26666667 0.23137255 0.14117647\n",
      "  0.21568627 0.28627451 0.23921569 0.4        0.45490196 0.34509804\n",
      "  0.38039216 0.44313725 0.45098039 0.38823529 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.29803922 0.24705882 0.15294118 0.15686275 0.17254902 0.1372549\n",
      "  0.28235294 0.21960784 0.30588235 0.38823529 0.29019608 0.29803922\n",
      "  0.33333333 0.23921569 0.24705882 0.54901961 0.44705882 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.10196078\n",
      "  0.25490196 0.18039216 0.18431373 0.17254902 0.16470588 0.17254902\n",
      "  0.14117647 0.24705882 0.29803922 0.2        0.24705882 0.28627451\n",
      "  0.21960784 0.30588235 0.38823529 0.34509804 0.61176471 0.07058824\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.17254902\n",
      "  0.21568627 0.25098039 0.18039216 0.16470588 0.18823529 0.17254902\n",
      "  0.16862745 0.23529412 0.23137255 0.20784314 0.21568627 0.28235294\n",
      "  0.3372549  0.30588235 0.2745098  0.33333333 0.51764706 0.2\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.14901961\n",
      "  0.2        0.3372549  0.18039216 0.1254902  0.18039216 0.16862745\n",
      "  0.18431373 0.23137255 0.26666667 0.21568627 0.27058824 0.37254902\n",
      "  0.30196078 0.30196078 0.40392157 0.46666667 0.49411765 0.28235294\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.16470588\n",
      "  0.14117647 0.49803922 0.41960784 0.08627451 0.16862745 0.15686275\n",
      "  0.19215686 0.26666667 0.24705882 0.20392157 0.24705882 0.25490196\n",
      "  0.3372549  0.32156863 0.62352941 0.44705882 0.40392157 0.29803922\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.22352941\n",
      "  0.11764706 0.38039216 0.90196078 0.05098039 0.15686275 0.18039216\n",
      "  0.21568627 0.25098039 0.23921569 0.21960784 0.2627451  0.29803922\n",
      "  0.34509804 0.25098039 0.74117647 0.41568627 0.40392157 0.32156863\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.23921569\n",
      "  0.14901961 0.18431373 0.88627451 0.05882353 0.15686275 0.18823529\n",
      "  0.23529412 0.23137255 0.23921569 0.22352941 0.28235294 0.28235294\n",
      "  0.30588235 0.22352941 0.87843137 0.36078431 0.31372549 0.36470588\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.23921569\n",
      "  0.20784314 0.10588235 0.79607843 0.10196078 0.16470588 0.16470588\n",
      "  0.24705882 0.24705882 0.21568627 0.21960784 0.27058824 0.31372549\n",
      "  0.28627451 0.2745098  1.         0.30196078 0.30588235 0.38431373\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00392157 0.22352941\n",
      "  0.21960784 0.14117647 0.5254902  0.13333333 0.16470588 0.16862745\n",
      "  0.24705882 0.25098039 0.23137255 0.20392157 0.25490196 0.29803922\n",
      "  0.25098039 0.23137255 0.92156863 0.30196078 0.29803922 0.36862745\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.02745098 0.25098039\n",
      "  0.19215686 0.23921569 0.21568627 0.16470588 0.15686275 0.16862745\n",
      "  0.23529412 0.25098039 0.25490196 0.19215686 0.25098039 0.2745098\n",
      "  0.24705882 0.18823529 0.92941176 0.32156863 0.23529412 0.34509804\n",
      "  0.00392157 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.03921569 0.24705882\n",
      "  0.16862745 0.26666667 0.30588235 0.15686275 0.15686275 0.15686275\n",
      "  0.23921569 0.24705882 0.25098039 0.20784314 0.20784314 0.2745098\n",
      "  0.2627451  0.16470588 0.78039216 0.36470588 0.21568627 0.31372549\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.05490196 0.25098039\n",
      "  0.19215686 0.30588235 0.33333333 0.14901961 0.16470588 0.18431373\n",
      "  0.20784314 0.21960784 0.22352941 0.22352941 0.18823529 0.27058824\n",
      "  0.23137255 0.23921569 0.22352941 0.45098039 0.21960784 0.31372549\n",
      "  0.01176471 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.05882353 0.23137255\n",
      "  0.22352941 0.31372549 0.27058824 0.1372549  0.16470588 0.2\n",
      "  0.18431373 0.21568627 0.21568627 0.21568627 0.2        0.23921569\n",
      "  0.21960784 0.23529412 0.31372549 0.43137255 0.2        0.32156863\n",
      "  0.03921569 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.05490196 0.2\n",
      "  0.24705882 0.32941176 0.21568627 0.10980392 0.17254902 0.16862745\n",
      "  0.19215686 0.23921569 0.21568627 0.18823529 0.2        0.21960784\n",
      "  0.21960784 0.25490196 0.19215686 0.30196078 0.38431373 0.2745098\n",
      "  0.03529412 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.06666667 0.18431373\n",
      "  0.28627451 0.36078431 0.15686275 0.1254902  0.16470588 0.15686275\n",
      "  0.2        0.24705882 0.21960784 0.17254902 0.18823529 0.20784314\n",
      "  0.2        0.2627451  0.07058824 0.42745098 0.43137255 0.20392157\n",
      "  0.05882353 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.05490196 0.14901961\n",
      "  0.32941176 0.3372549  0.00784314 0.18431373 0.14901961 0.15686275\n",
      "  0.22352941 0.21568627 0.23137255 0.2        0.17254902 0.20392157\n",
      "  0.2        0.23529412 0.0745098  0.45490196 0.32941176 0.2\n",
      "  0.09019608 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.08235294 0.11764706\n",
      "  0.38431373 0.28235294 0.00784314 0.20392157 0.13333333 0.17254902\n",
      "  0.20784314 0.17254902 0.22352941 0.20392157 0.18039216 0.16470588\n",
      "  0.15686275 0.23529412 0.0745098  0.44705882 0.33333333 0.16862745\n",
      "  0.10196078 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.08627451 0.10196078\n",
      "  0.39607843 0.30588235 0.05098039 0.18039216 0.13333333 0.2\n",
      "  0.14901961 0.22352941 0.2        0.17254902 0.20784314 0.2\n",
      "  0.16470588 0.21568627 0.0745098  0.43529412 0.38823529 0.1372549\n",
      "  0.10196078 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.08627451 0.08627451\n",
      "  0.42745098 0.20392157 0.05098039 0.15686275 0.18039216 0.14901961\n",
      "  0.15294118 0.27058824 0.19215686 0.17254902 0.16862745 0.18823529\n",
      "  0.17254902 0.20392157 0.05490196 0.30588235 0.46666667 0.1254902\n",
      "  0.10980392 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.09019608 0.09411765\n",
      "  0.56470588 0.12156863 0.03529412 0.18431373 0.16470588 0.10196078\n",
      "  0.30588235 0.23921569 0.18039216 0.18431373 0.15686275 0.16470588\n",
      "  0.15686275 0.19215686 0.07058824 0.3372549  0.43137255 0.11764706\n",
      "  0.12156863 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.10980392 0.13333333\n",
      "  0.39607843 0.16470588 0.03529412 0.15686275 0.10980392 0.17254902\n",
      "  0.27058824 0.14901961 0.20392157 0.18039216 0.17254902 0.17254902\n",
      "  0.16470588 0.17254902 0.09411765 0.30588235 0.41176471 0.10196078\n",
      "  0.1254902  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.11764706 0.10196078\n",
      "  0.39607843 0.23137255 0.05882353 0.15686275 0.14901961 0.18823529\n",
      "  0.18039216 0.15686275 0.19215686 0.18039216 0.17254902 0.16470588\n",
      "  0.14117647 0.20392157 0.05098039 0.30196078 0.49411765 0.10980392\n",
      "  0.17254902 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.1372549  0.1254902\n",
      "  0.43529412 0.22352941 0.         0.18823529 0.18823529 0.25490196\n",
      "  0.27058824 0.16862745 0.20392157 0.19215686 0.18431373 0.20392157\n",
      "  0.19215686 0.18039216 0.         0.29803922 0.47843137 0.1372549\n",
      "  0.14901961 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04313725 0.10196078\n",
      "  0.12156863 0.10588235 0.15294118 0.1372549  0.13333333 0.09019608\n",
      "  0.02745098 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10f2cb040>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "who=0\n",
    "who=getRandomIndex( x_train )\n",
    "\n",
    "print(\"who=\", who)\n",
    "\n",
    "print( y_train[who])\n",
    "print( x_train[who])\n",
    "plt.imshow(x_train[who], plt.cm.binary) \n",
    "plt.imshow(x_train[who] ) \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLVE USING RANDOM FORESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "new_x_train = []\n",
    "for i in x_train :\n",
    "    new_x_train.append( i.flatten() )\n",
    "new_x_train = np.array( new_x_train )\n",
    "\n",
    "new_x_test = []\n",
    "for i in x_test :\n",
    "    new_x_test.append( i.flatten() )\n",
    "new_x_test = np.array( new_x_test )\n",
    "\n",
    "print( x_train.shape )\n",
    "print( new_x_train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time =  873.5348052978516\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "theTrees = int( 2*TOTAL_SIZE )\n",
    "\n",
    "clf = RandomForestClassifier( n_estimators = theTrees )\n",
    "clf.fit( new_x_train, y_train )\n",
    "\n",
    "print(\"Execution Time = \", (time.time()-start_time) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "train accuracy 1.0\n",
      "9\n",
      "test accuracy 0.8781\n"
     ]
    }
   ],
   "source": [
    "pred_train = clf.predict( new_x_train )\n",
    "print( pred_train[0] )\n",
    "RF_acc_train = metrics.accuracy_score(y_train, pred_train )\n",
    "print( \"train accuracy\", RF_acc_train )\n",
    "\n",
    "pred_test = clf.predict( new_x_test )\n",
    "print( pred_test[0] )\n",
    "RF_acc = metrics.accuracy_score(y_test, pred_test )\n",
    "print( \"test accuracy\", RF_acc )\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLVE USING TENSOR FLOW NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "theEpochs = 50\n",
    "\n",
    "theActivation = tf.keras.activations.relu\n",
    "\n",
    "\n",
    "units_01 = int( 2*TOTAL_SIZE )\n",
    "units_02 = units_01\n",
    "\n",
    "DENSE_LAYER_01 = tf.keras.layers.Dense( units=units_01, activation=theActivation )\n",
    "DENSE_LAYER_02 = tf.keras.layers.Dense( units=units_02, activation=theActivation )\n",
    "DENSE_LAYER_XX = tf.keras.layers.Dense(10, activation=tf.nn.softmax )\n",
    "\n",
    "DROPOUT_LAYER = tf.keras.layers.Dropout( 0.2 )\n",
    "\n",
    "\n",
    "theOptimizer = tf.keras.optimizers.Adam()\n",
    "theLossMetric = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "theSplit = 0.3\n",
    "theBatchSize = 32\n",
    "verboseFlag = True\n",
    "\n",
    "theTensorFlowSaveFile = \"TF_Number_Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.5249 - accuracy: 0.8088 - val_loss: 0.4330 - val_accuracy: 0.8384\n",
      "Epoch 2/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.4050 - accuracy: 0.8515 - val_loss: 0.3842 - val_accuracy: 0.8583\n",
      "Epoch 3/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.3710 - accuracy: 0.8615 - val_loss: 0.3564 - val_accuracy: 0.8711\n",
      "Epoch 4/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.3459 - accuracy: 0.8714 - val_loss: 0.3365 - val_accuracy: 0.8762\n",
      "Epoch 5/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.3305 - accuracy: 0.8760 - val_loss: 0.3298 - val_accuracy: 0.8805\n",
      "Epoch 6/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.3147 - accuracy: 0.8828 - val_loss: 0.3346 - val_accuracy: 0.8809\n",
      "Epoch 7/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.3063 - accuracy: 0.8850 - val_loss: 0.3244 - val_accuracy: 0.8862\n",
      "Epoch 8/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2969 - accuracy: 0.8884 - val_loss: 0.3768 - val_accuracy: 0.8689\n",
      "Epoch 9/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2828 - accuracy: 0.8940 - val_loss: 0.3417 - val_accuracy: 0.8756\n",
      "Epoch 10/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2809 - accuracy: 0.8948 - val_loss: 0.3346 - val_accuracy: 0.8849\n",
      "Epoch 11/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2710 - accuracy: 0.8978 - val_loss: 0.3177 - val_accuracy: 0.8876\n",
      "Epoch 12/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2682 - accuracy: 0.8992 - val_loss: 0.3226 - val_accuracy: 0.8898\n",
      "Epoch 13/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2573 - accuracy: 0.9032 - val_loss: 0.3283 - val_accuracy: 0.8906\n",
      "Epoch 14/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2535 - accuracy: 0.9039 - val_loss: 0.3484 - val_accuracy: 0.8804\n",
      "Epoch 15/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2482 - accuracy: 0.9072 - val_loss: 0.3330 - val_accuracy: 0.8918\n",
      "Epoch 16/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2448 - accuracy: 0.9064 - val_loss: 0.3404 - val_accuracy: 0.8861\n",
      "Epoch 17/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2375 - accuracy: 0.9100 - val_loss: 0.3261 - val_accuracy: 0.8949\n",
      "Epoch 18/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2319 - accuracy: 0.9125 - val_loss: 0.3335 - val_accuracy: 0.8913\n",
      "Epoch 19/50\n",
      "1313/1313 [==============================] - 15s 11ms/step - loss: 0.2294 - accuracy: 0.9124 - val_loss: 0.3313 - val_accuracy: 0.8924\n",
      "Epoch 20/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2272 - accuracy: 0.9143 - val_loss: 0.3216 - val_accuracy: 0.8979\n",
      "Epoch 21/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2269 - accuracy: 0.9153 - val_loss: 0.3439 - val_accuracy: 0.8854\n",
      "Epoch 22/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2253 - accuracy: 0.9175 - val_loss: 0.3342 - val_accuracy: 0.8898\n",
      "Epoch 23/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2150 - accuracy: 0.9182 - val_loss: 0.3392 - val_accuracy: 0.8921\n",
      "Epoch 24/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2118 - accuracy: 0.9204 - val_loss: 0.3460 - val_accuracy: 0.8908\n",
      "Epoch 25/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2086 - accuracy: 0.9201 - val_loss: 0.3514 - val_accuracy: 0.8934\n",
      "Epoch 26/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2055 - accuracy: 0.9234 - val_loss: 0.3516 - val_accuracy: 0.8891\n",
      "Epoch 27/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2049 - accuracy: 0.9228 - val_loss: 0.3495 - val_accuracy: 0.8987\n",
      "Epoch 28/50\n",
      "1313/1313 [==============================] - 14s 10ms/step - loss: 0.2019 - accuracy: 0.9235 - val_loss: 0.3631 - val_accuracy: 0.8941\n",
      "Epoch 29/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.2005 - accuracy: 0.9247 - val_loss: 0.3437 - val_accuracy: 0.8949\n",
      "Epoch 30/50\n",
      "1313/1313 [==============================] - 15s 11ms/step - loss: 0.1955 - accuracy: 0.9253 - val_loss: 0.3629 - val_accuracy: 0.8904\n",
      "Epoch 31/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1966 - accuracy: 0.9269 - val_loss: 0.3651 - val_accuracy: 0.8934\n",
      "Epoch 32/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1933 - accuracy: 0.9280 - val_loss: 0.3842 - val_accuracy: 0.8937\n",
      "Epoch 33/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1914 - accuracy: 0.9286 - val_loss: 0.3800 - val_accuracy: 0.8964\n",
      "Epoch 34/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1829 - accuracy: 0.9303 - val_loss: 0.3798 - val_accuracy: 0.8935\n",
      "Epoch 35/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1856 - accuracy: 0.9296 - val_loss: 0.4094 - val_accuracy: 0.8892\n",
      "Epoch 36/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1875 - accuracy: 0.9312 - val_loss: 0.3657 - val_accuracy: 0.8939\n",
      "Epoch 37/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1788 - accuracy: 0.9337 - val_loss: 0.3865 - val_accuracy: 0.8940\n",
      "Epoch 38/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1764 - accuracy: 0.9333 - val_loss: 0.3868 - val_accuracy: 0.8916\n",
      "Epoch 39/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1801 - accuracy: 0.9331 - val_loss: 0.3973 - val_accuracy: 0.8950\n",
      "Epoch 40/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1817 - accuracy: 0.9306 - val_loss: 0.3742 - val_accuracy: 0.8968\n",
      "Epoch 41/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1750 - accuracy: 0.9348 - val_loss: 0.3881 - val_accuracy: 0.8961\n",
      "Epoch 42/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1748 - accuracy: 0.9346 - val_loss: 0.3951 - val_accuracy: 0.8993\n",
      "Epoch 43/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1691 - accuracy: 0.9358 - val_loss: 0.4301 - val_accuracy: 0.8957\n",
      "Epoch 44/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1704 - accuracy: 0.9356 - val_loss: 0.4235 - val_accuracy: 0.8984\n",
      "Epoch 45/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1701 - accuracy: 0.9357 - val_loss: 0.4176 - val_accuracy: 0.8947\n",
      "Epoch 46/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1739 - accuracy: 0.9355 - val_loss: 0.3857 - val_accuracy: 0.8976\n",
      "Epoch 47/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1656 - accuracy: 0.9378 - val_loss: 0.4035 - val_accuracy: 0.8958\n",
      "Epoch 48/50\n",
      "1313/1313 [==============================] - 14s 10ms/step - loss: 0.1666 - accuracy: 0.9376 - val_loss: 0.4325 - val_accuracy: 0.8986\n",
      "Epoch 49/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1621 - accuracy: 0.9389 - val_loss: 0.4063 - val_accuracy: 0.9009\n",
      "Epoch 50/50\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.1658 - accuracy: 0.9387 - val_loss: 0.4288 - val_accuracy: 0.8964\n",
      "Execution Time =  706.3839461803436\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build the Model\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add( tf.keras.layers.Flatten( input_shape=INPUT_SHAPE ) )\n",
    "model.add( DENSE_LAYER_01 )\n",
    "model.add( DROPOUT_LAYER )\n",
    "model.add( DENSE_LAYER_02 )\n",
    "model.add( DENSE_LAYER_XX )\n",
    "# model.compile( optimizer=theOptimizer, loss=theLossMetric )\n",
    "model.compile( optimizer=theOptimizer, loss=theLossMetric, metrics=['accuracy'] )\n",
    "# model.fit(x_train, y_train, epochs=theEpochs, verbose = verboseFlag )\n",
    "model.fit(x_train, y_train, epochs=theEpochs, validation_split=theSplit, batch_size=theBatchSize, verbose = verboseFlag )\n",
    "\n",
    "\n",
    "print(\"Execution Time = \", (time.time()-start_time) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHO =  1000  Predicted = 0  Actual =  0\n",
      "WHO =  6625  Predicted = 8  Actual =  2\n",
      "WHO =  6726  Predicted = 3  Actual =  3\n",
      "WHO =  526  Predicted = 4  Actual =  4\n",
      "WHO =  9653  Predicted = 0  Actual =  0\n",
      " --------- \n",
      "accuracy =  0.8873\n"
     ]
    }
   ],
   "source": [
    "probs = model.predict( x_test )\n",
    "\n",
    "pred_list = []\n",
    "for p in probs :\n",
    "    pred_list.append( np.argmax( p ) )\n",
    "pred = np.array( pred_list )\n",
    "acc_score = metrics.accuracy_score( y_test, pred)\n",
    "\n",
    "for i in range(5) :\n",
    "    who = getRandomIndex( x_test )\n",
    "    print(\"WHO = \", who, \" Predicted =\", pred[who], \" Actual = \", y_test[who] )\n",
    "\n",
    "print(\" --------- \")\n",
    "print(\"accuracy = \", acc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4717 - accuracy: 0.8873\n",
      "loss= 0.4717339873313904\n",
      "accuracy 0.8873000144958496\n"
     ]
    }
   ],
   "source": [
    "NN_loss, NN_acc = model.evaluate( x_test, y_test )\n",
    "print(\"loss=\",NN_loss)\n",
    "print(\"accuracy\",NN_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: TF_Number_Model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save( theTensorFlowSaveFile )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model= tf.keras.models.load_model( theTensorFlowSaveFile )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict( x_test ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9998260e-01 4.7283114e-14 7.7661616e-07 2.1396127e-09 5.1746684e-12\n",
      " 1.5040620e-17 1.6681608e-05 3.5198962e-24 1.1646302e-13 1.8438536e-27]\n",
      "predict= 0 actual= 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "who=getRandomIndex( x_test )\n",
    "print( predictions[who]) # probability score\n",
    "result = np.argmax( list(predictions[who]) )\n",
    "print(\"predict=\",result,\"actual=\",y_test[who])\n",
    "plt.imshow( x_test[who], plt.cm.binary )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of RANDOM FOREST and NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF accuracy 0.8781\n",
      "NN accuracy 0.8873000144958496\n"
     ]
    }
   ],
   "source": [
    "print(\"RF accuracy\", RF_acc )\n",
    "print(\"NN accuracy\",NN_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:catdogenv]",
   "language": "python",
   "name": "conda-env-catdogenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
