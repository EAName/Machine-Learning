{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG DATA\n",
      "TRAINING =  (4768, 66)\n",
      "TEST =  (1192, 66)\n",
      "       TARGET_BAD_FLAG  TARGET_LOSS_AMT\n",
      "count            951.0       951.000000\n",
      "mean               1.0     13431.187171\n",
      "std                0.0     11017.838362\n",
      "min                1.0       320.000000\n",
      "25%                1.0      5553.500000\n",
      "50%                1.0     10889.000000\n",
      "75%                1.0     17625.500000\n",
      "max                1.0     78987.000000\n",
      "       TARGET_BAD_FLAG  TARGET_LOSS_AMT\n",
      "count            238.0       238.000000\n",
      "mean               1.0     13348.205882\n",
      "std                0.0     10117.079640\n",
      "min                1.0       224.000000\n",
      "25%                1.0      5906.000000\n",
      "50%                1.0     11873.000000\n",
      "75%                1.0     17731.750000\n",
      "max                1.0     57029.000000\n",
      "\n",
      "\n",
      "\n",
      "       TARGET_BAD_FLAG  TARGET_LOSS_AMT\n",
      "count            951.0       951.000000\n",
      "mean               1.0     11247.786540\n",
      "std                0.0      6338.913914\n",
      "min                1.0       320.000000\n",
      "25%                1.0      5553.500000\n",
      "50%                1.0     10889.000000\n",
      "75%                1.0     17625.500000\n",
      "max                1.0     20000.000000\n",
      "       TARGET_BAD_FLAG  TARGET_LOSS_AMT\n",
      "count            238.0       238.000000\n",
      "mean               1.0     11554.693277\n",
      "std                0.0      6368.202034\n",
      "min                1.0       224.000000\n",
      "25%                1.0      5906.000000\n",
      "50%                1.0     11873.000000\n",
      "75%                1.0     17731.750000\n",
      "max                1.0     20000.000000\n",
      "\n",
      "\n",
      "\n",
      " ====== \n",
      "AMOUNT DATA\n",
      "TRAINING =  (951, 66)\n",
      "TEST =  (238, 2)\n",
      "REG_ALL RMSE ACCURACY\n",
      "======\n",
      "REG_ALL_Train  =  2578.1149234230306\n",
      "REG_ALL  =  2928.303347718223\n",
      "------\n",
      "\n",
      "\n",
      "REG_TREE RMSE ACCURACY\n",
      "======\n",
      "REG_TREE_Train  =  3304.0658752771515\n",
      "REG_TREE  =  3859.7207894640073\n",
      "------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('TRUNC_M_DEBTINC', 100)\n",
      "('TRUNC_IMP_DEBTINC', 85)\n",
      "('TRUNC_IMP_VALUE', 67)\n",
      "('TRUNC_IMP_CLAGE', 62)\n",
      "('TRUNC_LOAN', 53)\n",
      "('TRUNC_IMP_DELINQ', 48)\n",
      "('TRUNC_IMP_CLNO', 47)\n",
      "('TRUNC_IMP_MORTDUE', 46)\n",
      "('TRUNC_IMP_YOJ', 39)\n",
      "('TRUNC_IMP_DEROG', 25)\n",
      "('TRUNC_IMP_NINQ', 24)\n",
      "('O_M_VALUE', 15)\n",
      "('O_IMP_DELINQ', 11)\n",
      "\n",
      "\n",
      "\n",
      "('TRUNC_LOAN', 100)\n",
      "('TRUNC_IMP_CLNO', 17)\n",
      "('TRUNC_IMP_DEBTINC', 8)\n",
      "('TRUNC_M_DEBTINC', 6)\n",
      "('TRUNC_IMP_CLAGE', 4)\n",
      "REG_RF RMSE ACCURACY\n",
      "======\n",
      "REG_RF_Train  =  3131.6620583836875\n",
      "REG_RF  =  3610.5354895569426\n",
      "------\n",
      "\n",
      "\n",
      "\n",
      "CRASH\n",
      "---------\n",
      "Total Variables:  14\n",
      "INTERCEPT  =  -4.578312581129306\n",
      "TRUNC_M_DEBTINC  =  2.5459334032098786\n",
      "TRUNC_IMP_DEBTINC  =  0.0946946722026712\n",
      "TRUNC_IMP_VALUE  =  1.3895768672547687e-06\n",
      "TRUNC_IMP_CLAGE  =  -0.0069196117190507426\n",
      "TRUNC_LOAN  =  -7.686124308455325e-06\n",
      "TRUNC_IMP_DELINQ  =  0.6204051129661619\n",
      "TRUNC_IMP_CLNO  =  -0.0179085675429448\n",
      "TRUNC_IMP_MORTDUE  =  -4.3843942081225966e-07\n",
      "TRUNC_IMP_YOJ  =  -0.02087636491040614\n",
      "TRUNC_IMP_DEROG  =  0.6733537623908408\n",
      "TRUNC_IMP_NINQ  =  0.12012464170629926\n",
      "O_M_VALUE  =  3.567116296124259\n",
      "O_IMP_DELINQ  =  1.6271746770895223\n",
      "\n",
      "DAMAGES\n",
      "---------\n",
      "Total Variables:  6\n",
      "INTERCEPT  =  -5421.445133513547\n",
      "TRUNC_LOAN  =  0.40227147802723917\n",
      "TRUNC_IMP_CLNO  =  229.26899295916536\n",
      "TRUNC_IMP_DEBTINC  =  143.12813852406597\n",
      "TRUNC_M_DEBTINC  =  3638.561485569871\n",
      "TRUNC_IMP_CLAGE  =  -15.897689666292365\n",
      "\n",
      "\n",
      "\n",
      "('TRUNC_M_DEBTINC', 100)\n",
      "('TRUNC_IMP_DEBTINC', 29)\n",
      "('TRUNC_IMP_CLAGE', 18)\n",
      "('TRUNC_IMP_DELINQ', 16)\n",
      "('TRUNC_IMP_VALUE', 15)\n",
      "('TRUNC_IMP_CLNO', 6)\n",
      "('TRUNC_IMP_DEROG', 6)\n",
      "('TRUNC_LOAN', 4)\n",
      "('TRUNC_IMP_YOJ', 3)\n",
      "\n",
      "\n",
      "\n",
      "('TRUNC_LOAN', 100)\n",
      "('TRUNC_IMP_CLNO', 19)\n",
      "('TRUNC_M_DEBTINC', 9)\n",
      "('TRUNC_IMP_DEBTINC', 7)\n",
      "('TRUNC_IMP_CLAGE', 4)\n",
      "('TRUNC_IMP_DELINQ', 2)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "sns.set()\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "INFILE = \"~/Desktop/Edwin/Academic/Summer2022/MSDS422/Programming/A3/HMEQ_Loss.csv\"\n",
    "\n",
    "TARGET_F = \"TARGET_BAD_FLAG\"\n",
    "TARGET_A = \"TARGET_LOSS_AMT\"\n",
    "\n",
    "\n",
    "df = pd.read_csv( INFILE )\n",
    "\n",
    "dt = df.dtypes\n",
    "#print( dt )\n",
    "\n",
    "objList = []\n",
    "numList = []\n",
    "for i in dt.index :\n",
    "    #print(\" here is i .....\", i , \" ..... and here is the type\", dt[i] )\n",
    "    if i in ( [ TARGET_F, TARGET_A ] ) : continue\n",
    "    if dt[i] in ([\"object\"]) : objList.append( i )\n",
    "    if dt[i] in ([\"float64\",\"int64\"]) : numList.append( i )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "FILL IN MISSING WITH THE CATEGORY \"MISSING\"\n",
    "\"\"\"\n",
    "for i in objList :\n",
    "    if df[i].isna().sum() == 0 : continue\n",
    "    NAME = \"IMP_\"+i\n",
    "    df[NAME] = df[i]\n",
    "    df[NAME] = df[NAME].fillna(\"MISSING\")\n",
    "    g = df.groupby( NAME )\n",
    "    df = df.drop( i, axis=1 )\n",
    "\n",
    "dt = df.dtypes\n",
    "objList = []\n",
    "for i in dt.index :\n",
    "    #print(\" here is i .....\", i , \" ..... and here is the type\", dt[i] )\n",
    "    if i in ( [ TARGET_F, TARGET_A ] ) : continue\n",
    "    if dt[i] in ([\"object\"]) : objList.append( i )\n",
    "\n",
    "\n",
    "'''\n",
    "EXPLORE THE CATEGORICAL / OBJECT VARIABLES\n",
    "'''\n",
    "df[\"y_REASON_3\"] = (df.IMP_REASON.isin( [\"a_DebtCon\"] ) + 0 )\n",
    "df[\"y_REASON_2\"] = (df.IMP_JOB.isin( [\"a_DebtCon\",\"b_HomeImp\"] ) + 0)\n",
    "df[\"y_REASON_1\"] = (df.IMP_JOB.isin( [\"a_DebtCon\",\"b_HomeImp\",\"c_MISSING\"] ) + 0)\n",
    "df[\"y_JOB_7\"] = (df.IMP_JOB.isin( [\"a_Other\"] ) + 0 )\n",
    "df[\"y_JOB_6\"] = (df.IMP_JOB.isin( [\"a_Other\",\"b_MISSING\"] ) + 0)\n",
    "df[\"y_JOB_5\"] = (df.IMP_JOB.isin( [\"a_Other\",\"b_MISSING\",\"c_Office\"] ) + 0)\n",
    "df[\"y_JOB_4\"] = (df.IMP_JOB.isin( [\"a_Other\",\"b_MISSING\",\"c_Office\",\"d_Sales\"] ) + 0)\n",
    "df[\"y_JOB_3\"] = (df.IMP_JOB.isin( [\"a_Other\",\"b_MISSING\",\"c_Office\",\"d_Sales\",\"e_Mgr\"] ) + 0)\n",
    "df[\"y_JOB_2\"] = (df.IMP_JOB.isin( [\"a_Other\",\"b_MISSING\",\"c_Office\",\"d_Sales\",\"e_Mgr\",\"f_ProfExe\"] ) + 0)\n",
    "df[\"y_JOB_1\"] = (df.IMP_JOB.isin( [\"a_Other\",\"b_MISSING\",\"c_Office\",\"d_Sales\",\"e_Mgr\",\"f_ProfExe\",\"g_Self\"] ) + 0)\n",
    "# df = df.drop( \"IMP_JOB\", axis=1 )\n",
    "   \n",
    "\n",
    "dt = df.dtypes\n",
    "objList = []\n",
    "for i in dt.index :\n",
    "    #print(\" here is i .....\", i , \" ..... and here is the type\", dt[i] )\n",
    "    if i in ( [ TARGET_F, TARGET_A ] ) : continue\n",
    "    if dt[i] in ([\"object\"]) : objList.append( i )\n",
    "\n",
    "\n",
    "for i in objList :\n",
    "    thePrefix = \"z_\" + i\n",
    "    y = pd.get_dummies( df[i], prefix=thePrefix, drop_first=True )   \n",
    "    #y = pd.get_dummies( df[i], prefix=thePrefix )   \n",
    "    df = pd.concat( [df, y], axis=1 )\n",
    "    #df = df.drop( i, axis=1 )\n",
    "\n",
    "\n",
    "i = \"VALUE\"\n",
    "FLAG = \"M_\" + i\n",
    "IMP = \"IMP_\" + i\n",
    "#print( i )\n",
    "#print( FLAG )\n",
    "#print( IMP )\n",
    "df[ FLAG ] = df[i].isna() + 0\n",
    "df[ IMP ] = df[ i ]\n",
    "df.loc[ df[IMP].isna() & df[\"IMP_REASON\"].isin([\"DebtCon\"]), IMP ] = 3928\n",
    "df.loc[ df[IMP].isna() & df[\"IMP_REASON\"].isin([\"HomeImp\"]), IMP ] = 1780\n",
    "df.loc[ df[IMP].isna() & df[\"IMP_REASON\"].isin([\"MISSING\"]), IMP ] = 252\n",
    "df.loc[ df[IMP].isna() & df[\"IMP_JOB\"].isin([\"Mgr\"]), IMP ] = 767\n",
    "df.loc[ df[IMP].isna() & df[\"IMP_JOB\"].isin([\"Office\"]), IMP ] = 948\n",
    "df.loc[ df[IMP].isna() & df[\"IMP_JOB\"].isin([\"Other\"]), IMP ] = 2388\n",
    "df.loc[ df[IMP].isna() & df[\"IMP_JOB\"].isin([\"Doctor\"]), IMP ] = 1276\n",
    "df.loc[ df[IMP].isna() & df[\"IMP_JOB\"].isin([\"ProfExe\"]), IMP ] = 109\n",
    "df.loc[ df[IMP].isna() & df[\"IMP_JOB\"].isin([\"Sales\"]), IMP ] = 193\n",
    "df.loc[ df[IMP].isna(), IMP ] = df[i].median()\n",
    "df = df.drop( i, axis=1 )\n",
    "numList.remove(i)\n",
    "\n",
    "\n",
    "for i in numList :\n",
    "    if df[i].isna().sum() == 0 : continue\n",
    "    FLAG = \"M_\" + i\n",
    "    IMP = \"IMP_\" + i\n",
    "    #print(i)\n",
    "    #print( df[i].isna().sum() )\n",
    "    #print( FLAG )\n",
    "    #print( IMP )\n",
    "    #print(\" ------- \")\n",
    "    df[ FLAG ] = df[i].isna() + 0\n",
    "    df[ IMP ] = df[ i ]\n",
    "    df.loc[ df[IMP].isna(), IMP ] = df[i].median()\n",
    "    df = df.drop( i, axis=1 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Remove Outliers\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dt = df.dtypes\n",
    "numList = []\n",
    "for i in dt.index :\n",
    "    #print(i, dt[i])\n",
    "    if i in ( [ TARGET_F, TARGET_A ] ) : continue\n",
    "    if dt[i] in ([\"float64\",\"int64\"]) : numList.append( i )\n",
    "\n",
    "\n",
    "for i in numList :\n",
    "    theMean = df[i].mean()\n",
    "    theSD = df[i].std()\n",
    "    theMax = df[i].max()\n",
    "    theCutoff = round( theMean + 3*theSD )\n",
    "    if theMax < theCutoff : continue\n",
    "    FLAG = \"O_\" + i\n",
    "    TRUNC = \"TRUNC_\" + i\n",
    "    df[ FLAG ] = ( df[i] > theCutoff )+ 0\n",
    "    df[ TRUNC ] = df[ i ]\n",
    "    df.loc[ df[TRUNC] > theCutoff, TRUNC ] = theCutoff\n",
    "    df = df.drop( i, axis=1 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in objList:\n",
    "    df = df.drop( i, axis=1 )\n",
    "\n",
    "\"\"\"\n",
    "SPLIT DATA\n",
    "\"\"\"\n",
    "\n",
    "X = df.copy()\n",
    "X = X.drop( TARGET_F, axis=1 )\n",
    "X = X.drop( TARGET_A, axis=1 )\n",
    "\n",
    "Y = df[ [TARGET_F, TARGET_A] ]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2 )\n",
    "\n",
    "print( \"FLAG DATA\" )\n",
    "print( \"TRAINING = \", X_train.shape )\n",
    "print( \"TEST = \", X_test.shape )\n",
    "\n",
    "\n",
    "F = ~ Y_train[ TARGET_A ].isna()\n",
    "W_train = X_train[F].copy()\n",
    "Z_train = Y_train[F].copy()\n",
    "\n",
    "F = ~ Y_test[ TARGET_A ].isna()\n",
    "W_test = X_test[F].copy()\n",
    "Z_test = Y_test[F].copy()\n",
    "\n",
    "print( Z_train.describe() )\n",
    "print( Z_test.describe() )\n",
    "print( \"\\n\\n\")\n",
    "\n",
    "F = Z_train[ TARGET_A ] > 20000\n",
    "Z_train.loc[ F, TARGET_A ] = 20000\n",
    "\n",
    "F = Z_test[ TARGET_A ] > 20000\n",
    "Z_test.loc[ F, [TARGET_A] ] = 20000\n",
    "\n",
    "print( Z_train.describe() )\n",
    "print( Z_test.describe() )\n",
    "print( \"\\n\\n\")\n",
    "\n",
    "\n",
    "print( \" ====== \")\n",
    "\n",
    "print( \"AMOUNT DATA\" )\n",
    "print( \"TRAINING = \", W_train.shape )\n",
    "print( \"TEST = \", Z_test.shape )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "MODEL ACCURACY METRICS\n",
    "\"\"\"\n",
    "\n",
    "def getProbAccuracyScores( NAME, MODEL, X, Y ) :\n",
    "    pred = MODEL.predict( X )\n",
    "    probs = MODEL.predict_proba( X )\n",
    "    acc_score = metrics.accuracy_score(Y, pred)\n",
    "    p1 = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve( Y, p1)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    return [NAME, acc_score, fpr, tpr, auc]\n",
    "\n",
    "def print_ROC_Curve( TITLE, LIST ) :\n",
    "    pass\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    plt.title( TITLE )\n",
    "    for theResults in LIST :\n",
    "        NAME = theResults[0]\n",
    "        fpr = theResults[2]\n",
    "        tpr = theResults[3]\n",
    "        auc = theResults[4]\n",
    "        theLabel = \"AUC \" + NAME + ' %0.2f' % auc\n",
    "        plt.plot(fpr, tpr, label = theLabel )\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "def print_Accuracy( TITLE, LIST ) :\n",
    "    print( TITLE )\n",
    "    print( \"======\" )\n",
    "    for theResults in LIST :\n",
    "        NAME = theResults[0]\n",
    "        ACC = theResults[1]\n",
    "        print( NAME, \" = \", ACC )\n",
    "    print( \"------\\n\\n\" )\n",
    "\n",
    "def getAmtAccuracyScores( NAME, MODEL, X, Y ) :\n",
    "    pred = MODEL.predict( X )\n",
    "    MEAN = Y.mean()\n",
    "    RMSE = math.sqrt( metrics.mean_squared_error( Y, pred))\n",
    "    return [NAME, RMSE, MEAN]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##\"\"\"\n",
    "##DECISION TREE\n",
    "##\"\"\"\n",
    "\n",
    "def getTreeVars( TREE, varNames ) :\n",
    "    tree_ = TREE.tree_\n",
    "    varName = [ varNames[i] if i != _tree.TREE_UNDEFINED else \"undefined!\" for i in tree_.feature ]\n",
    "\n",
    "    nameSet = set()\n",
    "    for i in tree_.feature :\n",
    "        if i != _tree.TREE_UNDEFINED :\n",
    "            nameSet.add( i )\n",
    "    nameList = list( nameSet )\n",
    "    parameter_list = list()\n",
    "    for i in nameList :\n",
    "        parameter_list.append( varNames[i] )\n",
    "    return parameter_list\n",
    "\n",
    "\n",
    "\n",
    "# CRASH PROBABILITY\n",
    "\n",
    "WHO = \"TREE\"\n",
    "\n",
    "CLM = tree.DecisionTreeClassifier( max_depth=4 )\n",
    "CLM = CLM.fit( X_train, Y_train[ TARGET_F ] )\n",
    "\n",
    "TRAIN_CLM = getProbAccuracyScores( WHO + \"_Train\", CLM, X_train, Y_train[ TARGET_F ] )\n",
    "TEST_CLM = getProbAccuracyScores( WHO, CLM, X_test, Y_test[ TARGET_F ] )\n",
    "\n",
    "#print_ROC_Curve( WHO, [ TRAIN_CLM, TEST_CLM ] ) \n",
    "#print_Accuracy( WHO + \" CLASSIFICATION ACCURACY\", [ TRAIN_CLM, TEST_CLM ] )\n",
    "\n",
    "feature_cols = list( X.columns.values )\n",
    "tree.export_graphviz(CLM,out_file='tree_f.txt',filled=True, rounded=True, feature_names = feature_cols, impurity=False, class_names=[\"Good\",\"Bad\"]  )\n",
    "vars_tree_flag = getTreeVars( CLM, feature_cols ) \n",
    "\n",
    "\n",
    "# DAMAGES\n",
    "\n",
    "AMT = tree.DecisionTreeRegressor( max_depth= 4 )\n",
    "AMT = AMT.fit( W_train, Z_train[TARGET_A] )\n",
    "\n",
    "TRAIN_AMT = getAmtAccuracyScores( WHO + \"_Train\", AMT, W_train, Z_train[TARGET_A] )\n",
    "TEST_AMT = getAmtAccuracyScores( WHO, AMT, W_test, Z_test[TARGET_A] )\n",
    "#print_Accuracy( WHO + \" RMSE ACCURACY\", [ TRAIN_AMT, TEST_AMT ] )\n",
    "\n",
    "feature_cols = list( X.columns.values )\n",
    "vars_tree_amt = getTreeVars( AMT, feature_cols ) \n",
    "tree.export_graphviz(AMT,out_file='tree_a.txt',filled=True, rounded=True, feature_names = feature_cols, impurity=False, precision=0  )\n",
    "\n",
    "\n",
    "TREE_CLM = TEST_CLM.copy()\n",
    "TREE_AMT = TEST_AMT.copy()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "RANDOM FOREST\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def getEnsembleTreeVars( ENSTREE, varNames ) :\n",
    "    importance = ENSTREE.feature_importances_\n",
    "    index = np.argsort(importance)\n",
    "    theList = []\n",
    "    for i in index :\n",
    "        imp_val = importance[i]\n",
    "        if imp_val > np.average( ENSTREE.feature_importances_ ) :\n",
    "            v = int( imp_val / np.max( ENSTREE.feature_importances_ ) * 100 )\n",
    "            theList.append( ( varNames[i], v ) )\n",
    "    theList = sorted(theList,key=itemgetter(1),reverse=True)\n",
    "    return theList\n",
    "\n",
    "WHO = \"RF\"\n",
    "\n",
    "CLM = RandomForestClassifier( n_estimators = 25, random_state=1 )\n",
    "CLM = CLM.fit( X_train, Y_train[ TARGET_F ] )\n",
    "\n",
    "TRAIN_CLM = getProbAccuracyScores( WHO + \"_Train\", CLM, X_train, Y_train[ TARGET_F ] )\n",
    "TEST_CLM = getProbAccuracyScores( WHO, CLM, X_test, Y_test[ TARGET_F ] )\n",
    "\n",
    "#print_ROC_Curve( WHO, [ TRAIN_CLM, TEST_CLM ] ) \n",
    "#print_Accuracy( WHO + \" CLASSIFICATION ACCURACY\", [ TRAIN_CLM, TEST_CLM ] )\n",
    "\n",
    "\n",
    "feature_cols = list( X.columns.values )\n",
    "vars_RF_flag = getEnsembleTreeVars( CLM, feature_cols )\n",
    "\n",
    "\n",
    "# DAMAGES\n",
    "\n",
    "AMT = RandomForestRegressor(n_estimators = 100, random_state=1)\n",
    "AMT = AMT.fit( W_train, Z_train[TARGET_A] )\n",
    "\n",
    "TRAIN_AMT = getAmtAccuracyScores( WHO + \"_Train\", AMT, W_train, Z_train[TARGET_A] )\n",
    "TEST_AMT = getAmtAccuracyScores( WHO, AMT, W_test, Z_test[TARGET_A] )\n",
    "#print_Accuracy( WHO + \" RMSE ACCURACY\", [ TRAIN_AMT, TEST_AMT ] )\n",
    "\n",
    "feature_cols = list( X.columns.values )\n",
    "vars_RF_amt = getEnsembleTreeVars( AMT, feature_cols )\n",
    "\n",
    "##for i in vars_RF_amt :\n",
    "##    print( i )\n",
    "\n",
    "RF_CLM = TEST_CLM.copy()\n",
    "RF_AMT = TEST_AMT.copy()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "GRADIENT BOOSTING\n",
    "\"\"\"\n",
    "\n",
    "WHO = \"GB\"\n",
    "\n",
    "CLM = GradientBoostingClassifier( random_state=1 )\n",
    "CLM = CLM.fit( X_train, Y_train[ TARGET_F ] )\n",
    "\n",
    "TRAIN_CLM = getProbAccuracyScores( WHO + \"_Train\", CLM, X_train, Y_train[ TARGET_F ] )\n",
    "TEST_CLM = getProbAccuracyScores( WHO, CLM, X_test, Y_test[ TARGET_F ] )\n",
    "\n",
    "#print_ROC_Curve( WHO, [ TRAIN_CLM, TEST_CLM ] ) \n",
    "#print_Accuracy( WHO + \" CLASSIFICATION ACCURACY\", [ TRAIN_CLM, TEST_CLM ] )\n",
    "\n",
    "\n",
    "feature_cols = list( X.columns.values )\n",
    "vars_GB_flag = getEnsembleTreeVars( CLM, feature_cols )\n",
    "\n",
    "\n",
    "# DAMAGES\n",
    "\n",
    "AMT = GradientBoostingRegressor(random_state=1)\n",
    "AMT = AMT.fit( W_train, Z_train[TARGET_A] )\n",
    "\n",
    "TRAIN_AMT = getAmtAccuracyScores( WHO + \"_Train\", AMT, W_train, Z_train[TARGET_A] )\n",
    "TEST_AMT = getAmtAccuracyScores( WHO, AMT, W_test, Z_test[TARGET_A] )\n",
    "#print_Accuracy( WHO + \" RMSE ACCURACY\", [ TRAIN_AMT, TEST_AMT ] )\n",
    "\n",
    "feature_cols = list( X.columns.values )\n",
    "vars_GB_amt = getEnsembleTreeVars( AMT, feature_cols )\n",
    "\n",
    "##for i in vars_RF_amt :\n",
    "##    print( i )\n",
    "\n",
    "GB_CLM = TEST_CLM.copy()\n",
    "GB_AMT = TEST_AMT.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getCoefLogit( MODEL, TRAIN_DATA ) :\n",
    "    varNames = list( TRAIN_DATA.columns.values )\n",
    "    coef_dict = {}\n",
    "    coef_dict[\"INTERCEPT\"] = MODEL.intercept_[0]\n",
    "    for coef, feat in zip(MODEL.coef_[0],varNames):\n",
    "        coef_dict[feat] = coef\n",
    "    print(\"\\nCRASH\")\n",
    "    print(\"---------\")\n",
    "    print(\"Total Variables: \", len( coef_dict ) )\n",
    "    for i in coef_dict :\n",
    "        print( i, \" = \", coef_dict[i]  )\n",
    "\n",
    "\n",
    "\n",
    "def getCoefLinear( MODEL, TRAIN_DATA ) :\n",
    "    varNames = list( TRAIN_DATA.columns.values )\n",
    "    coef_dict = {}\n",
    "    coef_dict[\"INTERCEPT\"] = MODEL.intercept_\n",
    "    for coef, feat in zip(MODEL.coef_,varNames):\n",
    "        coef_dict[feat] = coef\n",
    "    print(\"\\nDAMAGES\")\n",
    "    print(\"---------\")\n",
    "    print(\"Total Variables: \", len( coef_dict ) )\n",
    "    for i in coef_dict :\n",
    "        print( i, \" = \", coef_dict[i]  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "REGRESSION ALL VARIABLES\n",
    "\"\"\"\n",
    "\n",
    "WHO = \"REG_ALL\"\n",
    "\n",
    "CLM = LogisticRegression( solver='newton-cg', max_iter=1000 )\n",
    "CLM = CLM.fit( X_train, Y_train[ TARGET_F ] )\n",
    "\n",
    "TRAIN_CLM = getProbAccuracyScores( WHO + \"_Train\", CLM, X_train, Y_train[ TARGET_F ] )\n",
    "TEST_CLM = getProbAccuracyScores( WHO, CLM, X_test, Y_test[ TARGET_F ] )\n",
    "\n",
    "#print_ROC_Curve( WHO, [ TRAIN_CLM, TEST_CLM ] ) \n",
    "#print_Accuracy( WHO + \" CLASSIFICATION ACCURACY\", [ TRAIN_CLM, TEST_CLM ] )\n",
    "\n",
    "\n",
    "# DAMAGES\n",
    "\n",
    "AMT = LinearRegression()\n",
    "AMT = AMT.fit( W_train, Z_train[TARGET_A] )\n",
    "\n",
    "TRAIN_AMT = getAmtAccuracyScores( WHO + \"_Train\", AMT, W_train, Z_train[TARGET_A] )\n",
    "TEST_AMT = getAmtAccuracyScores( WHO, AMT, W_test, Z_test[TARGET_A] )\n",
    "print_Accuracy( WHO + \" RMSE ACCURACY\", [ TRAIN_AMT, TEST_AMT ] )\n",
    "\n",
    "\n",
    "varNames = list( X_train.columns.values )\n",
    "\n",
    "#REG_ALL_CLM_COEF = getCoefLogit( CLM, X_train )\n",
    "#REG_ALL_AMT_COEF = getCoefLinear( AMT, X_train )\n",
    "\n",
    "REG_ALL_CLM = TEST_CLM.copy()\n",
    "REG_ALL_AMT = TEST_AMT.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "REGRESSION DECISION TREE\n",
    "\"\"\"\n",
    "\n",
    "WHO = \"REG_TREE\"\n",
    "\n",
    "CLM = LogisticRegression( solver='newton-cg', max_iter=1000 )\n",
    "CLM = CLM.fit( X_train[vars_tree_flag], Y_train[ TARGET_F ] )\n",
    "\n",
    "TRAIN_CLM = getProbAccuracyScores( WHO + \"_Train\", CLM, X_train[vars_tree_flag], Y_train[ TARGET_F ] )\n",
    "TEST_CLM = getProbAccuracyScores( WHO, CLM, X_test[vars_tree_flag], Y_test[ TARGET_F ] )\n",
    "\n",
    "#print_ROC_Curve( WHO, [ TRAIN_CLM, TEST_CLM ] ) \n",
    "#print_Accuracy( WHO + \" CLASSIFICATION ACCURACY\", [ TRAIN_CLM, TEST_CLM ] )\n",
    "\n",
    "\n",
    "# DAMAGES\n",
    "\n",
    "AMT = LinearRegression()\n",
    "AMT = AMT.fit( W_train[vars_tree_amt], Z_train[TARGET_A] )\n",
    "\n",
    "TRAIN_AMT = getAmtAccuracyScores( WHO + \"_Train\", AMT, W_train[vars_tree_amt], Z_train[TARGET_A] )\n",
    "TEST_AMT = getAmtAccuracyScores( WHO, AMT, W_test[vars_tree_amt], Z_test[TARGET_A] )\n",
    "print_Accuracy( WHO + \" RMSE ACCURACY\", [ TRAIN_AMT, TEST_AMT ] )\n",
    "\n",
    "\n",
    "varNames = list( X_train.columns.values )\n",
    "\n",
    "#REG_TREE_CLM_COEF = getCoefLogit( CLM, X_train[vars_tree_flag] )\n",
    "#REG_TREE_AMT_COEF = getCoefLinear( AMT, X_train[vars_tree_amt] )\n",
    "\n",
    "REG_TREE_CLM = TEST_CLM.copy()\n",
    "REG_TREE_AMT = TEST_AMT.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "REGRESSION RANDOM FOREST\n",
    "\"\"\"\n",
    "\n",
    "WHO = \"REG_RF\"\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "RF_flag = []\n",
    "for i in vars_RF_flag :\n",
    "    print(i)\n",
    "    theVar = i[0]\n",
    "    RF_flag.append( theVar )\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "RF_amt = []\n",
    "for i in vars_RF_amt :\n",
    "    print(i)\n",
    "    theVar = i[0]\n",
    "    RF_amt.append( theVar )\n",
    "\n",
    "\n",
    "CLM = LogisticRegression( solver='newton-cg', max_iter=1000 )\n",
    "CLM = CLM.fit( X_train[RF_flag], Y_train[ TARGET_F ] )\n",
    "\n",
    "TRAIN_CLM = getProbAccuracyScores( WHO + \"_Train\", CLM, X_train[RF_flag], Y_train[ TARGET_F ] )\n",
    "TEST_CLM = getProbAccuracyScores( WHO, CLM, X_test[RF_flag], Y_test[ TARGET_F ] )\n",
    "\n",
    "#print_ROC_Curve( WHO, [ TRAIN_CLM, TEST_CLM ] ) \n",
    "#print_Accuracy( WHO + \" CLASSIFICATION ACCURACY\", [ TRAIN_CLM, TEST_CLM ] )\n",
    "\n",
    "\n",
    "# DAMAGES\n",
    "\n",
    "AMT = LinearRegression()\n",
    "AMT = AMT.fit( W_train[RF_amt], Z_train[TARGET_A] )\n",
    "\n",
    "TRAIN_AMT = getAmtAccuracyScores( WHO + \"_Train\", AMT, W_train[RF_amt], Z_train[TARGET_A] )\n",
    "TEST_AMT = getAmtAccuracyScores( WHO, AMT, W_test[RF_amt], Z_test[TARGET_A] )\n",
    "print_Accuracy( WHO + \" RMSE ACCURACY\", [ TRAIN_AMT, TEST_AMT ] )\n",
    "\n",
    "\n",
    "REG_RF_CLM_COEF = getCoefLogit( CLM, X_train[RF_flag] )\n",
    "REG_RF_AMT_COEF = getCoefLinear( AMT, X_train[RF_amt] )\n",
    "\n",
    "REG_RF_CLM = TEST_CLM.copy()\n",
    "REG_RF_AMT = TEST_AMT.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "REGRESSION GRADIENT BOOSTING\n",
    "\"\"\"\n",
    "\n",
    "WHO = \"REG_GB\"\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "GB_flag = []\n",
    "for i in vars_GB_flag :\n",
    "    print(i)\n",
    "    theVar = i[0]\n",
    "    GB_flag.append( theVar )\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "GB_amt = []\n",
    "for i in vars_GB_amt :\n",
    "    print(i)\n",
    "    theVar = i[0]\n",
    "    GB_amt.append( theVar )\n",
    "\n",
    "\n",
    "CLM = LogisticRegression( solver='newton-cg', max_iter=1000 )\n",
    "CLM = CLM.fit( X_train[GB_flag], Y_train[ TARGET_F ] )\n",
    "\n",
    "TRAIN_CLM = getProbAccuracyScores( WHO + \"_Train\", CLM, X_train[GB_flag], Y_train[ TARGET_F ] )\n",
    "TEST_CLM = getProbAccuracyScores( WHO, CLM, X_test[GB_flag], Y_test[ TARGET_F ] )\n",
    "\n",
    "#print_ROC_Curve( WHO, [ TRAIN_CLM, TEST_CLM ] ) \n",
    "#print_Accuracy( WHO + \" CLASSIFICATION ACCURACY\", [ TRAIN_CLM, TEST_CLM ] )\n",
    "\n",
    "\n",
    "# DAMAGES\n",
    "\n",
    "AMT = LinearRegression()\n",
    "AMT = AMT.fit( W_train[GB_amt], Z_train[TARGET_A] )\n",
    "\n",
    "TRAIN_AMT = getAmtAccuracyScores( WHO + \"_Train\", AMT, W_train[GB_amt], Z_train[TARGET_A] )\n",
    "TEST_AMT = getAmtAccuracyScores( WHO, AMT, W_test[GB_amt], Z_test[TARGET_A] )\n",
    "print_Accuracy( WHO + \" RMSE ACCURACY\", [ TRAIN_AMT, TEST_AMT ] )\n",
    "\n",
    "REG_GB_CLM_COEF = getCoefLogit( CLM, X_train[GB_flag] )\n",
    "REG_GB_AMT_COEF = getCoefLinear( AMT, X_train[GB_amt] )\n",
    "\n",
    "REG_GB_CLM = TEST_CLM.copy()\n",
    "REG_GB_AMT = TEST_AMT.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##\"\"\"\n",
    "##REGRESSION STEPWISE\n",
    "##\"\"\"\n",
    "##\n",
    "##U_train = X_train[ vars_tree_flag ]\n",
    "##stepVarNames = list( U_train.columns.values )\n",
    "##maxCols = U_train.shape[1]\n",
    "##\n",
    "##sfs = SFS( LogisticRegression( solver='newton-cg', max_iter=100 ),\n",
    "##           k_features=( 1, maxCols ),\n",
    "##           forward=True,\n",
    "##           floating=False,\n",
    "##           cv=3\n",
    "##           )\n",
    "##sfs.fit(U_train.values, Y_train[ TARGET_F ].values)\n",
    "##\n",
    "##theFigure = plot_sfs(sfs.get_metric_dict(), kind=None )\n",
    "##plt.title('CRASH PROBABILITY Sequential Forward Selection (w. StdErr)')\n",
    "##plt.grid()\n",
    "##plt.show()\n",
    "##\n",
    "##dfm = pd.DataFrame.from_dict( sfs.get_metric_dict()).T\n",
    "##dfm = dfm[ ['feature_names', 'avg_score'] ]\n",
    "##dfm.avg_score = dfm.avg_score.astype(float)\n",
    "##\n",
    "##print(\" ................... \")\n",
    "##maxIndex = dfm.avg_score.argmax()\n",
    "##print(\"argmax\")\n",
    "##print( dfm.iloc[ maxIndex, ] )\n",
    "##print(\" ................... \")\n",
    "##\n",
    "##stepVars = dfm.iloc[ maxIndex, ]\n",
    "##stepVars = stepVars.feature_names\n",
    "##print( stepVars )\n",
    "##\n",
    "##finalStepVars = []\n",
    "##for i in stepVars :\n",
    "##    index = int(i)\n",
    "##    try :\n",
    "##        theName = stepVarNames[ index ]\n",
    "##        finalStepVars.append( theName )\n",
    "##    except :\n",
    "##        pass\n",
    "##\n",
    "##for i in finalStepVars :\n",
    "##    print(i)\n",
    "##\n",
    "##U_train = X_train[ finalStepVars ]\n",
    "##U_test = X_test[ finalStepVars ]\n",
    "##\n",
    "##\n",
    "##\n",
    "##V_train = W_train[ GB_amt ]\n",
    "##stepVarNames = list( V_train.columns.values )\n",
    "##maxCols = V_train.shape[1]\n",
    "##\n",
    "##sfs = SFS( LinearRegression(),\n",
    "##           k_features=( 1, maxCols ),\n",
    "##           forward=True,\n",
    "##           floating=False,\n",
    "##           scoring = 'r2',\n",
    "##           cv=5\n",
    "##           )\n",
    "##sfs.fit(V_train.values, Z_train[ TARGET_A ].values)\n",
    "##\n",
    "##theFigure = plot_sfs(sfs.get_metric_dict(), kind=None )\n",
    "##plt.title('DAMAGES Sequential Forward Selection (w. StdErr)')\n",
    "##plt.grid()\n",
    "##plt.show()\n",
    "##\n",
    "##dfm = pd.DataFrame.from_dict( sfs.get_metric_dict()).T\n",
    "##dfm = dfm[ ['feature_names', 'avg_score'] ]\n",
    "##dfm.avg_score = dfm.avg_score.astype(float)\n",
    "##\n",
    "##print(\" ................... \")\n",
    "##maxIndex = dfm.avg_score.argmax()\n",
    "##print(\"argmax\")\n",
    "##print( dfm.iloc[ maxIndex, ] )\n",
    "##print(\" ................... \")\n",
    "##\n",
    "##stepVars = dfm.iloc[ maxIndex, ]\n",
    "##stepVars = stepVars.feature_names\n",
    "##print( stepVars )\n",
    "##\n",
    "##finalStepVars = []\n",
    "##for i in stepVars :\n",
    "##    index = int(i)\n",
    "##    try :\n",
    "##        theName = stepVarNames[ index ]\n",
    "##        finalStepVars.append( theName )\n",
    "##    except :\n",
    "##        pass\n",
    "##\n",
    "##for i in finalStepVars :\n",
    "##    print(i)\n",
    "##\n",
    "##V_train = W_train[ finalStepVars ]\n",
    "##V_test = W_test[ finalStepVars ]\n",
    "##\n",
    "##\n",
    "##\n",
    "##\"\"\"\n",
    "##REGRESSION \n",
    "##\"\"\"\n",
    "##\n",
    "##WHO = \"REG_STEPWISE\"\n",
    "##\n",
    "##CLM = LogisticRegression( solver='newton-cg', max_iter=1000 )\n",
    "##CLM = CLM.fit( U_train, Y_train[ TARGET_F ] )\n",
    "##\n",
    "##TRAIN_CLM = getProbAccuracyScores( WHO + \"_Train\", CLM, U_train, Y_train[ TARGET_F ] )\n",
    "##TEST_CLM = getProbAccuracyScores( WHO, CLM, U_test, Y_test[ TARGET_F ] )\n",
    "##\n",
    "##print_ROC_Curve( WHO, [ TRAIN_CLM, TEST_CLM ] ) \n",
    "##print_Accuracy( WHO + \" CLASSIFICATION ACCURACY\", [ TRAIN_CLM, TEST_CLM ] )\n",
    "##\n",
    "##\n",
    "### DAMAGES\n",
    "##\n",
    "##AMT = LinearRegression()\n",
    "##AMT = AMT.fit( V_train, Z_train[TARGET_A] )\n",
    "##\n",
    "##TRAIN_AMT = getAmtAccuracyScores( WHO + \"_Train\", AMT, V_train, Z_train[TARGET_A] )\n",
    "##TEST_AMT = getAmtAccuracyScores( WHO, AMT, V_test, Z_test[TARGET_A] )\n",
    "##print_Accuracy( WHO + \" RMSE ACCURACY\", [ TRAIN_AMT, TEST_AMT ] )\n",
    "##\n",
    "##REG_STEP_CLM_COEF = getCoefLogit( CLM, U_train )\n",
    "##REG_STEP_AMT_COEF = getCoefLinear( AMT, V_train )\n",
    "##\n",
    "##REG_STEP_CLM = TEST_CLM.copy()\n",
    "##REG_STEP_AMT = TEST_AMT.copy()\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "##\n",
    "##ALL_CLM = [ TREE_CLM, RF_CLM, GB_CLM, REG_ALL_CLM, REG_TREE_CLM, REG_RF_CLM, REG_GB_CLM, REG_STEP_CLM ]\n",
    "##\n",
    "##ALL_CLM = sorted( ALL_CLM, key = lambda x: x[4], reverse=True )\n",
    "##print_ROC_Curve( WHO, ALL_CLM ) \n",
    "##\n",
    "##ALL_CLM = sorted( ALL_CLM, key = lambda x: x[1], reverse=True )\n",
    "##print_Accuracy( \"ALL CLASSIFICATION ACCURACY\", ALL_CLM )\n",
    "##\n",
    "##\n",
    "##ALL_AMT = [ TREE_AMT, RF_AMT, GB_AMT, REG_ALL_AMT, REG_TREE_AMT, REG_RF_AMT, REG_GB_AMT, REG_STEP_AMT ]\n",
    "##ALL_AMT = sorted( ALL_AMT, key = lambda x: x[1] )\n",
    "##print_Accuracy( \"ALL DAMAGE MODEL ACCURACY\", ALL_AMT )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "theScaler = MinMaxScaler()\n",
    "theScaler.fit( X_train )\n",
    "\n",
    "\n",
    "\n",
    "def get_TF_ProbAccuracyScores( NAME, MODEL, X, Y ) :\n",
    "    probs = MODEL.predict_proba( X )\n",
    "    pred_list = []\n",
    "    for p in probs :\n",
    "        pred_list.append( np.argmax( p ) )\n",
    "    pred = np.array( pred_list )\n",
    "    acc_score = metrics.accuracy_score(Y, pred)\n",
    "    p1 = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve( Y, p1)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    return [NAME, acc_score, fpr, tpr, auc]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "WHO = \"Tensor_FLow\"\n",
    "\n",
    "U_train = theScaler.transform( X_train )\n",
    "U_test = theScaler.transform( X_test )\n",
    "\n",
    "U_train = pd.DataFrame( U_train )\n",
    "U_test = pd.DataFrame( U_test )\n",
    "\n",
    "U_train.columns = list( X_train.columns.values )\n",
    "U_test.columns = list( X_train.columns.values )\n",
    "\n",
    "U_train = U_train[ GB_flag ]\n",
    "U_test = U_test[ GB_flag ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "F_theShapeSize = U_train.shape[1]\n",
    "F_theActivation = tf.keras.activations.relu\n",
    "F_theLossMetric = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "F_theOptimizer = tf.keras.optimizers.Adam()\n",
    "F_theEpochs = 100\n",
    "\n",
    "F_theUnits = int( 2*F_theShapeSize / 3 )\n",
    "\n",
    "F_LAYER_01 = tf.keras.layers.Dense( units=F_theUnits, activation=F_theActivation, input_dim=F_theShapeSize )\n",
    "F_LAYER_DROP = tf.keras.layers.Dropout( 0.2 )\n",
    "F_LAYER_02 = tf.keras.layers.Dense( units=F_theUnits, activation=F_theActivation )\n",
    "F_LAYER_OUTPUT = tf.keras.layers.Dense( units=2, activation=tf.keras.activations.softmax )\n",
    "\n",
    "\n",
    "CLM = tf.keras.Sequential()\n",
    "CLM.add( F_LAYER_01 )\n",
    "CLM.add( F_LAYER_DROP )\n",
    "CLM.add( F_LAYER_02 )\n",
    "CLM.add( F_LAYER_OUTPUT )\n",
    "CLM.compile( loss=F_theLossMetric, optimizer=F_theOptimizer)\n",
    "CLM.fit( U_train, Y_train[TARGET_F], epochs=F_theEpochs, verbose=False )\n",
    "\n",
    "TRAIN_CLM = get_TF_ProbAccuracyScores( WHO + \"_Train\", CLM, U_train, Y_train[ TARGET_F ] )\n",
    "TEST_CLM = get_TF_ProbAccuracyScores( WHO, CLM, U_test, Y_test[ TARGET_F ] )\n",
    "\n",
    "print_ROC_Curve( WHO, [ TRAIN_CLM, TEST_CLM ] ) \n",
    "print_Accuracy( WHO + \" CLASSIFICATION ACCURACY\", [ TRAIN_CLM, TEST_CLM ] )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "V_train = theScaler.transform( W_train )\n",
    "V_test = theScaler.transform( W_test )\n",
    "\n",
    "V_train = pd.DataFrame( V_train )\n",
    "V_test = pd.DataFrame( V_test )\n",
    "\n",
    "V_train.columns = list( W_train.columns.values )\n",
    "V_test.columns = list( W_train.columns.values )\n",
    "\n",
    "V_train = V_train[ GB_amt ]\n",
    "V_test = V_test[ GB_amt ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A_theShapeSize = V_train.shape[1]\n",
    "A_theActivation = tf.keras.activations.relu\n",
    "A_theLossMetric = tf.keras.losses.MeanSquaredError()\n",
    "A_theOptimizer = tf.keras.optimizers.Adam()\n",
    "A_theEpochs = 800\n",
    "\n",
    "A_theUnits = int( 2*A_theShapeSize  )\n",
    "\n",
    "A_LAYER_01 = tf.keras.layers.Dense( units=A_theUnits, activation=A_theActivation, input_dim=A_theShapeSize )\n",
    "A_LAYER_DROP = tf.keras.layers.Dropout( 0.2 )\n",
    "A_LAYER_02 = tf.keras.layers.Dense( units=A_theUnits, activation=A_theActivation )\n",
    "A_LAYER_OUTPUT = tf.keras.layers.Dense( units=1, activation=tf.keras.activations.linear )\n",
    "\n",
    "AMT = tf.keras.Sequential()\n",
    "AMT.add( A_LAYER_01 )\n",
    "AMT.add( A_LAYER_DROP )\n",
    "AMT.add( A_LAYER_02 )\n",
    "AMT.add( A_LAYER_OUTPUT )\n",
    "AMT.compile( loss=A_theLossMetric, optimizer=A_theOptimizer)\n",
    "AMT.fit( V_train, Z_train[TARGET_A], epochs=A_theEpochs, verbose=False )\n",
    "\n",
    "\n",
    "TRAIN_AMT = getAmtAccuracyScores( WHO + \"_Train\", AMT, V_train[GB_amt], Z_train[TARGET_A] )\n",
    "TEST_AMT = getAmtAccuracyScores( WHO, AMT, V_test[GB_amt], Z_test[TARGET_A] )\n",
    "print_Accuracy( WHO + \" RMSE ACCURACY\", [ TRAIN_AMT, TEST_AMT ] )\n",
    "\n",
    "TF_CLM = TEST_CLM.copy()\n",
    "TF_AMT = TEST_AMT.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ALL_CLM = [ TREE_CLM, RF_CLM, GB_CLM, REG_ALL_CLM, REG_TREE_CLM, REG_RF_CLM, REG_GB_CLM, TF_CLM ]\n",
    "\n",
    "ALL_CLM = sorted( ALL_CLM, key = lambda x: x[4], reverse=True )\n",
    "print_ROC_Curve( WHO, ALL_CLM ) \n",
    "\n",
    "ALL_CLM = sorted( ALL_CLM, key = lambda x: x[1], reverse=True )\n",
    "print_Accuracy( \"ALL CLASSIFICATION ACCURACY\", ALL_CLM )\n",
    "\n",
    "\n",
    "\n",
    "ALL_AMT = [ TREE_AMT, RF_AMT, GB_AMT, REG_ALL_AMT, REG_TREE_AMT, REG_RF_AMT, REG_GB_AMT, TF_AMT ]\n",
    "ALL_AMT = sorted( ALL_AMT, key = lambda x: x[1] )\n",
    "print_Accuracy( \"ALL DAMAGE MODEL ACCURACY\", ALL_AMT )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(action=\"ignore\", category=Warning )\n",
    "#warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "N = 1000\n",
    "\n",
    "X_List = []\n",
    "Y_List = []\n",
    "\n",
    "for i in range(N) :\n",
    "    A = random.randint( -10, 10 )\n",
    "    B = random.randint( -10, 10 )\n",
    "    Y_Val = 4*A - 3*B + 2 + random.normalvariate(0,1)\n",
    "    \n",
    "    X_List.append([A,B])\n",
    "    Y_List.append( Y_Val )\n",
    "\n",
    "\n",
    "\n",
    "X = np.array( X_List, dtype=\"f\" )\n",
    "Y = np.array( Y_List, dtype=\"f\" )\n",
    "\n",
    "\n",
    "\n",
    "regModel = LinearRegression()\n",
    "regModel.fit( X, Y  )\n",
    "A = round( regModel.coef_[0], 3 )\n",
    "B = round( regModel.coef_[1], 3 )\n",
    "INTERCEPT = round( regModel.intercept_, 3 )\n",
    "\n",
    "print(\"REGRESSION\")\n",
    "print( \"A   =\", A )\n",
    "print( \"B   =\", B )\n",
    "print( \"Bias=\", INTERCEPT )\n",
    "\n",
    "X_NEW = np.array( [[1,1]] )\n",
    "Y_NEW = regModel.predict( X_NEW )\n",
    "Y_NEW = np.round_( Y_NEW, 3 )\n",
    "print( \"X=\",X_NEW[0] )\n",
    "print( \"Y=\",Y_NEW[0] )\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "theShapeSize = X.shape[1]\n",
    "theActivation = tf.keras.activations.linear\n",
    "theLossMetric = tf.keras.losses.MeanSquaredError()\n",
    "theOptimizer = tf.keras.optimizers.Adam()\n",
    "theEpochs = 1000\n",
    "\n",
    "LAYER_01 = tf.keras.layers.Dense( units=1, activation=theActivation, input_dim=theShapeSize )\n",
    "\n",
    "##model = tf.keras.Sequential()\n",
    "##model.add( LAYER_01 )\n",
    "##model.compile( loss=theLossMetric,optimizer=theOptimizer)\n",
    "##model.fit( X, Y, epochs=theEpochs, verbose=False )\n",
    "##\n",
    "##W = LAYER_01.get_weights()\n",
    "##print(\"TENSOR FLOW\")\n",
    "##print( \"A   =\",round(W[0][0][0],3) )\n",
    "##print( \"B   =\",round(W[0][1][0],3) )\n",
    "##print( \"Bias=\",round(W[1][0]   ,3) )\n",
    "##\n",
    "##X_NEW = np.array( [[1,1]] )\n",
    "##Y_NEW = model.predict( X_NEW )\n",
    "##Y_NEW = np.round_( Y_NEW, 3 )\n",
    "##print( \"X=\",X_NEW[0] )\n",
    "##print( \"Y=\",Y_NEW[0] )\n",
    "##print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"REGRESSION\\n\\n\")\n",
    "for i in range( 10 ):\n",
    "    regModel = LinearRegression()\n",
    "    regModel.fit( X, Y  )\n",
    "    A = round( regModel.coef_[0], 3 )\n",
    "    B = round( regModel.coef_[1], 3 )\n",
    "    INTERCEPT = round( regModel.intercept_, 3 )\n",
    "\n",
    "    print(\"ITERATION \",i)\n",
    "    print( \"A   =\", A )\n",
    "    print( \"B   =\", B )\n",
    "    print( \"Bias=\", INTERCEPT )\n",
    "\n",
    "    X_NEW = np.array( [[1,1]] )\n",
    "    Y_NEW = regModel.predict( X_NEW )\n",
    "    Y_NEW = np.round_( Y_NEW, 3 )\n",
    "    print( \"X=\",X_NEW[0] )\n",
    "    print( \"Y=\",Y_NEW[0] )\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"TENSOR FLOW\\n\\n\")\n",
    "for i in range( 10 ):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add( LAYER_01 )\n",
    "    model.compile( loss=theLossMetric,optimizer=theOptimizer)\n",
    "    model.fit( X, Y, epochs=theEpochs, verbose=False )   \n",
    "\n",
    "    W = LAYER_01.get_weights()\n",
    "    print(\"ITERATION \",i)\n",
    "    print( \"A   =\",round(W[0][0][0],3) )\n",
    "    print( \"B   =\",round(W[0][1][0],3) )\n",
    "    print( \"Bias=\",round(W[1][0]   ,3) )\n",
    "\n",
    "    X_NEW = np.array( [[1,1]] )\n",
    "    Y_NEW = model.predict( X_NEW )\n",
    "    Y_NEW = np.round_( Y_NEW, 3 )\n",
    "    print( \"X=\",X_NEW[0] )\n",
    "    print( \"Y=\",Y_NEW[0] )\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399c43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
